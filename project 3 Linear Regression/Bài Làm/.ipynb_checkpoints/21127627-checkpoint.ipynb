{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Đồ án 3: Linear Regression</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thông tin sinh viên\n",
    "\n",
    "- Họ và tên: Cao Nguyễn Khánh\n",
    "- MSSV: 21127627\n",
    "- Lớp: 21CLC04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Import thêm dữ thư viện nếu cần"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu bằng pandas\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Lấy các đặc trưng X và giá trị mục tiêu y cho các tập huấn luyện (train) và kiểm tra (test)\n",
    "X_train = train.iloc[:, :-1]    # Dataframe (chứa 10 đặc trưng huấn luyện)\n",
    "y_train = train.iloc[:, -1]     # Series    (chứa 1 giá trị mục tiêu kiểm tra)\n",
    "\n",
    "X_test = test.iloc[:, :-1]      # Dataframe (chứa 10 đặc trưng kiểm tra)\n",
    "y_test = test.iloc[:, -1]       # Series    (chứa 1 giá trị mục tiêu kiểm tra)\n",
    "\n",
    "# Sinh viên có thể sử dụng các khác nếu cần"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cài đặt hàm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cài đặt các hàm cần thiết ở đây"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiền xử lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In ra 5 dòng đầu tiên của X_train với đầy đủ nội dung các cột\n",
    "# X_train = X_train.head()\n",
    "# y_train = y_train.head()\n",
    "\n",
    "# y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yêu cầu 1a: Sử dụng toàn bộ 11 đặc trưng đầu tiên `Gender`, `10percentage`, `12percentage`, `CollegeTier`, `Degree`, `collegeGPA`, `CollegeCityTier`, `English`, `Logical`, `Quant`, `Domain` (2 điểm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>10percentage</th>\n",
       "      <th>12percentage</th>\n",
       "      <th>CollegeTier</th>\n",
       "      <th>Degree</th>\n",
       "      <th>collegeGPA</th>\n",
       "      <th>CollegeCityTier</th>\n",
       "      <th>English</th>\n",
       "      <th>Logical</th>\n",
       "      <th>Quant</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>87.80</td>\n",
       "      <td>84.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73.82</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>665</td>\n",
       "      <td>810</td>\n",
       "      <td>0.694479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>57.00</td>\n",
       "      <td>64.50</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>65.00</td>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>435</td>\n",
       "      <td>210</td>\n",
       "      <td>0.342315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>77.33</td>\n",
       "      <td>85.17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>61.94</td>\n",
       "      <td>0</td>\n",
       "      <td>485</td>\n",
       "      <td>475</td>\n",
       "      <td>505</td>\n",
       "      <td>0.824666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>84.30</td>\n",
       "      <td>86.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>80.40</td>\n",
       "      <td>1</td>\n",
       "      <td>675</td>\n",
       "      <td>620</td>\n",
       "      <td>635</td>\n",
       "      <td>0.990009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>82.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64.30</td>\n",
       "      <td>1</td>\n",
       "      <td>575</td>\n",
       "      <td>495</td>\n",
       "      <td>365</td>\n",
       "      <td>0.278457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2243</th>\n",
       "      <td>1</td>\n",
       "      <td>91.00</td>\n",
       "      <td>73.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>85.00</td>\n",
       "      <td>0</td>\n",
       "      <td>555</td>\n",
       "      <td>445</td>\n",
       "      <td>485</td>\n",
       "      <td>0.916870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>2</td>\n",
       "      <td>75.00</td>\n",
       "      <td>73.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>70.00</td>\n",
       "      <td>1</td>\n",
       "      <td>505</td>\n",
       "      <td>485</td>\n",
       "      <td>445</td>\n",
       "      <td>0.538387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>2</td>\n",
       "      <td>84.00</td>\n",
       "      <td>77.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>75.20</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "      <td>585</td>\n",
       "      <td>395</td>\n",
       "      <td>0.190153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>1</td>\n",
       "      <td>91.40</td>\n",
       "      <td>65.56</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>73.19</td>\n",
       "      <td>0</td>\n",
       "      <td>385</td>\n",
       "      <td>425</td>\n",
       "      <td>485</td>\n",
       "      <td>0.600057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>1</td>\n",
       "      <td>88.64</td>\n",
       "      <td>65.16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>74.81</td>\n",
       "      <td>1</td>\n",
       "      <td>465</td>\n",
       "      <td>645</td>\n",
       "      <td>505</td>\n",
       "      <td>0.901490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2248 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  10percentage  12percentage  CollegeTier  Degree  collegeGPA  \\\n",
       "0          2         87.80         84.00            1       1       73.82   \n",
       "1          1         57.00         64.50            2       1       65.00   \n",
       "2          1         77.33         85.17            2       1       61.94   \n",
       "3          1         84.30         86.00            1       1       80.40   \n",
       "4          2         82.00         75.00            2       1       64.30   \n",
       "...      ...           ...           ...          ...     ...         ...   \n",
       "2243       1         91.00         73.00            2       2       85.00   \n",
       "2244       2         75.00         73.00            2       1       70.00   \n",
       "2245       2         84.00         77.00            2       1       75.20   \n",
       "2246       1         91.40         65.56            2       1       73.19   \n",
       "2247       1         88.64         65.16            2       1       74.81   \n",
       "\n",
       "      CollegeCityTier  English  Logical  Quant    Domain  \n",
       "0                   1      650      665    810  0.694479  \n",
       "1                   0      440      435    210  0.342315  \n",
       "2                   0      485      475    505  0.824666  \n",
       "3                   1      675      620    635  0.990009  \n",
       "4                   1      575      495    365  0.278457  \n",
       "...               ...      ...      ...    ...       ...  \n",
       "2243                0      555      445    485  0.916870  \n",
       "2244                1      505      485    445  0.538387  \n",
       "2245                0      345      585    395  0.190153  \n",
       "2246                0      385      425    485  0.600057  \n",
       "2247                1      465      645    505  0.901490  \n",
       "\n",
       "[2248 rows x 11 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Phần code cho yêu cầu 1a\n",
    "selected_features = ['Gender', '10percentage', '12percentage', 'CollegeTier', 'Degree',\n",
    "                     'collegeGPA', 'CollegeCityTier', 'English', 'Logical', 'Quant', 'Domain']\n",
    "# Chọn 11 cột đầu tiên của DataFrame X_train\n",
    "selected_columns = X_train.columns[:11]\n",
    "\n",
    "# Tạo DataFrame mới X_train11 với chỉ 11 cột đầu tiên\n",
    "X_train11 = X_train[selected_columns]\n",
    "X_test11 = X_test[selected_columns]\n",
    "X_train11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Xây dựng và huấn luyện mô hình hồi quy tuyến tính trên toàn bộ dữ liệu\n",
    "model1a = LinearRegression()\n",
    "model1a.fit(X_train11, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([194207.93160491, 340719.58717406, 325416.84861397, 273672.74799754,\n",
       "       298369.36726444, 352015.74694404, 234779.7619092 , 261961.54605652,\n",
       "       266112.40481144, 372849.64049772, 301599.21406001, 279946.54486441,\n",
       "       228413.01407561, 305770.45016173, 403117.84794154, 311514.75295673,\n",
       "       255771.6406102 , 249511.47496086, 282050.50784367, 342932.68002501,\n",
       "       252047.78684692, 331783.8543578 , 392592.81848188, 441556.83514415,\n",
       "       237549.86845078, 406144.5863516 , 325347.97152288, 340287.86083972,\n",
       "       339589.96608669, 359034.7906052 , 337830.75631687, 388921.75950567,\n",
       "       307399.94344879, 507243.30753988, 303046.98974608, 288503.42897022,\n",
       "       488343.13883449, 307550.03410941, 373338.98609063, 281018.74597146,\n",
       "       499929.31989583, 360613.09095212, 266862.5060087 , 386429.00791345,\n",
       "       236977.45662334, 391749.09033547, 312501.27630642, 255610.43006437,\n",
       "       474422.70383532, 300598.05757003, 293416.22841846, 369686.76439215,\n",
       "       250401.61675547, 297319.646986  , 317699.13103174, 280942.35692969,\n",
       "       296677.28367435, 220219.2427095 , 319905.03926839, 339179.83194951,\n",
       "       291781.78959537, 335708.58894483, 283343.39195623, 279435.45727477,\n",
       "       280726.04277099, 286159.37631493, 293741.54063723, 236386.39573205,\n",
       "       251322.58832039, 302029.29748788, 324637.135573  , 223775.41621017,\n",
       "       333188.84006747, 483297.87852363, 293496.49269205, 349633.60432309,\n",
       "       258139.37939055, 370208.06327623, 313751.81699371, 312001.44709543,\n",
       "       318694.70989913, 219051.03352202, 301555.91002305, 279694.17109972,\n",
       "       452067.50460907, 319643.08525245, 288707.82852097, 385061.04639344,\n",
       "       280132.41066898, 313117.17999547, 344269.11153898, 284152.33479575,\n",
       "       423893.3257664 , 359694.21962005, 310127.2821085 , 312593.67077829,\n",
       "       266826.879264  , 475865.24018996, 301668.62744018, 342020.15547451,\n",
       "       182370.13133828, 233753.48608481, 302912.60258595, 349505.62042816,\n",
       "       308745.52349613, 492630.34528667, 256308.41668323, 320505.16897085,\n",
       "       446401.48587324, 349836.59575333, 312366.60955465, 188588.94310013,\n",
       "       304220.05674191, 286248.30484756, 296912.69331365, 345076.19085987,\n",
       "       278427.84308568, 352707.86679535, 260594.20367277, 303238.8703971 ,\n",
       "       497594.52925137, 375719.16637905, 228666.58268479, 234453.48771152,\n",
       "       294293.0750601 , 326540.7665006 , 318944.38961692, 300104.38338804,\n",
       "       428609.24998469, 237739.42015328, 360302.45507506, 286210.81748303,\n",
       "       315691.95422663, 314397.73823439, 320625.80360976, 280249.83553991,\n",
       "       229646.34219048, 323948.8780638 , 290442.46026737, 382254.42170444,\n",
       "       199337.78394337, 264167.4002038 , 336735.09411153, 264354.42992744,\n",
       "       325004.30534287, 226908.35428017, 347915.35751969, 333727.83721436,\n",
       "       279642.08994598, 271897.30802291, 218511.14959764, 335276.63123739,\n",
       "       385245.01338873, 407764.71895458, 361676.49375288, 305369.52138657,\n",
       "       278174.15267412, 254211.3774352 , 412012.79873616, 383211.55047261,\n",
       "       283697.86742393, 347075.23502686, 357907.60657329, 349810.17021981,\n",
       "       178428.72283668, 314791.39444976, 289850.16176686, 270856.46632884,\n",
       "       278293.41450492, 222641.96528009, 316486.56633104, 277267.01253262,\n",
       "       334079.64079955, 216190.21619676, 448621.57356033, 314915.21659015,\n",
       "       288025.03778442, 300247.21772961, 203270.1903258 , 277598.41839835,\n",
       "       257239.32617981, 380503.56611825, 260595.73806474, 266006.07281053,\n",
       "       197278.24042094, 266686.95967435, 275393.39426103, 335828.68616799,\n",
       "       295257.02762133, 359869.97602545, 271929.11635499, 293782.14748754,\n",
       "       317183.21331865, 258368.77011922, 314633.35444721, 310062.90464052,\n",
       "       270970.34638366, 418488.76805894, 179128.45369158, 310632.05025943,\n",
       "       322063.35116113, 310558.1097893 , 315265.26155562, 336963.7815885 ,\n",
       "       344135.21463954, 303494.84361579, 202067.75040801, 234549.68118234,\n",
       "       335651.17278437, 197438.20371746, 326364.83553671, 375271.09737591,\n",
       "       372326.60817049, 306665.11526741, 269886.38739697, 256496.21784812,\n",
       "       246915.33204977, 294574.09521481, 393213.73940398, 456767.31705715,\n",
       "       313662.32023895, 342057.37834304, 237358.5376543 , 412817.67255811,\n",
       "       359492.99456771, 242277.03812138, 286141.67111439, 260694.32060461,\n",
       "       308914.84243268, 336761.29872499, 268579.46918145, 353828.26307495,\n",
       "       250453.61349793, 296612.72976985, 330483.19709863, 239524.1660076 ,\n",
       "       293374.00928713, 322545.30321109, 230609.84235535, 279692.34262739,\n",
       "       299335.81111653, 265106.15615455, 390748.89467909, 276862.25810458,\n",
       "       314145.15031955, 222707.39486695, 362808.57225891, 294403.62081258,\n",
       "       510759.35412733, 275283.43018008, 299022.35497895, 425488.90842725,\n",
       "       283058.2629742 , 314370.00331269, 181719.79689042, 271097.44401688,\n",
       "       300206.3050425 , 240255.91958413, 251704.54112037, 269778.53218371,\n",
       "       280904.44719854, 338952.35029779, 332608.70360537, 279023.4553802 ,\n",
       "       548218.57574137, 303585.77080211, 352969.47891153, 443465.98771365,\n",
       "       445016.23869889, 293663.88377801, 281961.2966065 , 385877.60576255,\n",
       "       323215.22082972, 304406.30718536, 300824.74971909, 261936.11142049,\n",
       "       250784.46599665, 258114.67187713, 246194.46202902, 294702.35443793,\n",
       "       304647.032485  , 290754.32321691, 302330.40458359, 322714.25233011,\n",
       "       275325.2603708 , 284664.50985861, 255311.53840492, 346291.41180486,\n",
       "       360387.10566696, 362676.18758073, 215762.79519337, 311714.06198177,\n",
       "       360532.96559994, 364584.75245983, 300867.63176023, 307978.49331436,\n",
       "       264575.75389986, 302949.09919191, 400490.8320882 , 291938.79966968,\n",
       "       327272.68866407, 407495.91263655, 408092.75656135, 384626.64409684,\n",
       "       165844.46241266, 403829.6092791 , 235255.44524617, 267066.99891043,\n",
       "       520377.53607484, 318111.64381123, 346695.70801351, 375495.16564141,\n",
       "       330522.30159125, 302584.24179477, 382026.05696197, 278977.32098879,\n",
       "       243360.07932472, 271045.6678396 , 239932.91879866, 364069.01543147,\n",
       "       327253.35135889, 327483.69505115, 280142.09457346, 329106.40799329,\n",
       "       288380.57041212, 381456.82620803, 386159.41833363, 289043.32365017,\n",
       "       233218.13196659, 314002.9896275 , 332988.11911046, 287839.54669207,\n",
       "       357317.65111773, 466355.39886239, 275440.67997257, 291360.56457295,\n",
       "       298715.52244467, 342646.0964442 , 352247.88185266, 289134.92523277,\n",
       "       358605.59171309, 408075.05537426, 217742.67588312, 319148.5281716 ,\n",
       "       562139.79358202, 270635.84354949, 229871.33948054, 306328.35926159,\n",
       "       293036.40640841, 307114.7203655 , 375932.80582833, 303362.87726492,\n",
       "       355884.57335205, 285021.91370684, 325736.77255882, 317399.22532549,\n",
       "       375264.908943  , 355239.3840616 , 402647.27224699, 316199.02971913,\n",
       "       219387.66253768, 373831.69869578, 326021.04017379, 344897.38470556,\n",
       "       292277.76704837, 238511.22352793, 342801.77103867, 183437.08938568,\n",
       "       233644.31337882, 324611.32553426, 306426.20894203, 380960.73054425,\n",
       "       302836.99686734, 222709.33944946, 273228.89978747, 212590.13447516,\n",
       "       199665.82346417, 260967.93982964, 295814.09804298, 210731.03725096,\n",
       "       296138.26718203, 341776.18905197, 200651.4450908 , 442092.72238529,\n",
       "       295742.9076757 , 372821.37578035, 336946.10619334, 293957.34945581,\n",
       "       292118.27615915, 281081.00943462, 201588.05516213, 439142.94327796,\n",
       "       300895.09626971, 204271.90942623, 237084.8733346 , 301932.85435367,\n",
       "       317703.31927927, 193567.5911681 , 164513.71383995, 308291.14512579,\n",
       "       295469.2867993 , 266185.22274225, 259065.50963867, 223419.16333277,\n",
       "       365030.22341384, 265419.37663634, 391732.03062811, 231586.51109697,\n",
       "       315104.32462796, 239054.25928812, 294248.58514321, 241694.49841072,\n",
       "       350801.95716168, 275755.40080382, 308300.06194592, 282889.47775134,\n",
       "       298764.7201588 , 383215.59706984, 270642.38404345, 293730.24355564,\n",
       "       239885.5555829 , 378668.90573958, 248443.24625044, 224971.90521451,\n",
       "       314391.50592759, 335948.34100391, 259694.75442558, 289582.00561081,\n",
       "       351739.93322287, 360791.1899645 , 448619.18259111, 281714.70059968,\n",
       "       284539.01784937, 317016.41923548, 303978.46848159, 363586.65588653,\n",
       "       248546.47698113, 351377.87447594, 349015.11398415, 316272.19777178,\n",
       "       162315.92255181, 333385.02686402, 336500.4046375 , 301460.18296169,\n",
       "       241322.00168345, 303308.35353482, 334919.44628983, 523889.39433955,\n",
       "       338005.47940095, 304199.13837671, 450527.76883879, 300572.03475728,\n",
       "       267964.59926967, 299080.4184589 , 239886.84732682, 212503.92453536,\n",
       "       211248.83483926, 357676.58956834, 299535.40397969, 272410.09317494,\n",
       "       185072.65402849, 307207.69919426, 327497.84869465, 202778.76591857,\n",
       "       388928.22517125, 361705.95861261, 303153.08874604, 193581.91966761,\n",
       "       452145.81968123, 339704.6203657 , 233130.10645091, 365595.43871276,\n",
       "       287067.47805462, 361800.87126849, 376042.98653766, 311505.50170082,\n",
       "       239735.59509037, 297185.65366879, 245059.69571267, 247967.1348698 ,\n",
       "       359477.85245151, 283087.91878264, 225733.57303482, 224825.83019207,\n",
       "       470297.35345729, 433594.73571496, 254943.75500005, 324183.9263774 ,\n",
       "       320701.60549759, 355828.85573299, 313262.69880527, 305149.47874779,\n",
       "       263178.74078925, 306609.76809817, 311340.52377716, 292298.96917253,\n",
       "       340978.47653521, 309724.39107527, 321442.93039514, 383503.68346873,\n",
       "       278735.61721186, 242593.24320178, 261685.59347109, 250287.46206823,\n",
       "       294518.3455348 , 236339.57155327, 321636.09020182, 323677.70044899,\n",
       "       242106.160585  , 286083.41053639, 492333.13331884, 321093.70374268,\n",
       "       314377.95691873, 338819.92327433, 275891.97508548, 244268.52047742,\n",
       "       311068.08028758, 243290.31143713, 260314.97160487, 360496.23070517,\n",
       "       366395.59497208, 366448.64028166, 300345.13874769, 299612.98879689,\n",
       "       441369.26109096, 413657.86032856, 303933.17623265, 453827.62351409,\n",
       "       269772.42142303, 437360.66513637, 331989.57105275, 267607.39799252,\n",
       "       233722.33146767, 247176.71521829, 290699.06836209, 287288.98439162,\n",
       "       202422.43117881, 532362.84314852, 275571.49175594, 356401.31125454,\n",
       "       426813.61710382, 350841.09432768, 401537.08480037, 356738.91357587,\n",
       "       392765.81686148, 278373.61820135, 336422.77119595, 327461.61799292,\n",
       "       400543.53799332, 363609.53663027, 313162.15605581, 316850.18597768,\n",
       "       381845.5478905 , 162958.8593887 , 308586.09454382, 304647.89748828,\n",
       "       297795.9033615 , 217211.31499786, 298093.83751137, 270322.3144407 ,\n",
       "       312948.86721928, 479083.68553724, 179038.88925094, 274977.10063765,\n",
       "       309875.71094478, 303062.68059708, 244167.23480213, 313693.07868177,\n",
       "       332905.24803715, 348619.61647113, 217004.14144491, 292265.31461483,\n",
       "       329423.77773066, 269242.98402453, 328203.93879749, 300184.18646035,\n",
       "       248430.30589201, 303905.36988651, 365510.93109731, 274798.34714735,\n",
       "       289333.0993846 , 267457.28324582, 266730.72255306, 473717.31565032,\n",
       "       329103.33554283, 264421.29168079, 358235.51922504, 359134.46785497,\n",
       "       368421.520681  , 254215.21937024, 417558.88347573, 362200.22386806,\n",
       "       287018.78070742, 253711.71129997, 256720.20253806, 362036.98580269,\n",
       "       411897.57990264, 333941.18103676, 329498.76298123, 303199.01336197,\n",
       "       293179.14172058, 283813.66549113, 377001.11298562, 223294.14932758,\n",
       "       216039.61828992, 286962.89118321, 525412.23768474, 271848.52546751,\n",
       "       255898.80059336, 275331.46068992, 258159.5050566 , 269426.78550301,\n",
       "       272954.22534394, 363725.70689853, 332794.40807538, 238768.27289287,\n",
       "       279687.17916595, 377649.04673754, 340569.0016482 , 376367.44331947,\n",
       "       288493.03569706, 249429.91431133, 264354.19875418, 400539.58148359,\n",
       "       312653.71567004, 364282.73367948, 252988.6341235 , 434435.23470443,\n",
       "       240697.52632704, 422554.73071333, 266345.53216998, 278945.65701636,\n",
       "       283791.69676047, 266369.08585108, 256358.07881615, 304763.15203967,\n",
       "       297325.68718602, 260944.20506728, 267338.94565226, 254728.25970647,\n",
       "       352610.2472631 , 359154.55620058, 326547.71311859, 301116.5026104 ,\n",
       "       230154.33707654, 243443.17704591, 260587.77361908, 287020.22977596,\n",
       "       251191.43278947, 285477.34653102, 505526.35531931, 293472.26274823,\n",
       "       325503.19284904, 310190.31449652, 222332.39245064, 271112.70660963,\n",
       "       255040.17763141, 303296.60464596, 291070.79818485, 269428.85228556,\n",
       "       362731.72832617, 352295.11965059, 407183.30012384, 308409.80479777,\n",
       "       351254.73872332, 398889.08016283, 146798.21357225, 274080.98131463,\n",
       "       288841.65287004, 258961.09531367, 223376.17791681, 434102.37936626,\n",
       "       311681.79775297, 307957.39677197, 271437.21991433, 281469.36434152,\n",
       "       346185.15123344, 338452.86304072, 277612.40244864, 266061.83784549,\n",
       "       292938.07695861, 198553.72389369, 364399.63204022, 285421.29229118,\n",
       "       265810.17703686, 315272.67105206, 251443.8849672 , 216233.44702217,\n",
       "       459300.19678979, 186836.60975292, 293886.06734127, 203648.09304652,\n",
       "       263412.52134613, 343715.48545906, 300158.05529457, 315335.90618127,\n",
       "       471279.29915758, 280300.39996045, 316069.83072685, 330353.54066135,\n",
       "       385327.18719464, 200353.47640884, 232454.12063858, 324514.92246402,\n",
       "       474466.54410065, 377983.03990996, 364133.35923435, 330529.68411819,\n",
       "       267039.33790319, 276644.33712529, 188229.9030599 , 257149.10856033,\n",
       "       293979.29008681, 297632.60915269, 326725.06976536, 197710.61509505,\n",
       "       340374.72695243, 314565.83944956, 291309.19301289, 396763.73104876,\n",
       "       294415.03186927, 294444.05354253, 346720.9590924 , 320785.65515383,\n",
       "       344282.25007788, 361303.082762  , 353647.53984047, 294128.84567504,\n",
       "       340851.40597367, 379800.51141849, 223510.52263487, 319539.9367016 ,\n",
       "       328007.57504322, 279071.22499377, 348103.26366054, 405579.27334147,\n",
       "       283160.99519576, 360061.99183023, 360410.50319902, 255936.68841523,\n",
       "       341257.55195729, 307750.2450469 , 315072.73078169, 274980.99139471,\n",
       "       388162.8143073 , 283138.70577918, 381114.17967311, 297490.12294855,\n",
       "       242061.85433391, 328403.65309115])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test = X_test.head()\n",
    "# Dự đoán giá trị mức lương trên toàn bộ dữ liệu\n",
    "y_pred1a = model1a.predict(X_test11)\n",
    "\n",
    "y_pred1a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary = 49248.09 + -23183.330*Gender + 702.767*10percentage + 1259.019*12percentage + -99570.608*CollegeTier + 18369.962*Degree + 1297.532*collegeGPA + -8836.727*CollegeCityTier + 141.760*English + 145.742*Logical + 114.643*Quant + 34955.750*Domain \n"
     ]
    }
   ],
   "source": [
    "def CTMoHinh(model, selected_features): \n",
    "    # In ra công thức của mô hình hồi quy\n",
    "    coefficients = model.coef_\n",
    "    \n",
    "    formula = \"Salary = {:.2f} + \".format(model.intercept_)  # Hệ số chặn\n",
    "    for i, coef in enumerate(coefficients):\n",
    "        feature_name = selected_features[i]\n",
    "        formula += \"{:.3f}*{} + \".format(coef, feature_name)\n",
    "    formula = formula[:-2]  # Loại bỏ dấu + cuối cùng\n",
    "    return formula\n",
    "    \n",
    "print(CTMoHinh(model1a, selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 105052.52978823172\n"
     ]
    }
   ],
   "source": [
    "# Gọi hàm MAE (tự cài đặt hoặc từ thư viện) trên tập kiểm tra\n",
    "# Đánh giá hiệu suất mô hình trên toàn bộ dữ liệu\n",
    "mae1a = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae1a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Công thức hồi quy (phần trọng số làm tròn đến 3 chữ số thập phân, ví dụ 0.012345 $\\to$ 0.012)\n",
    "\n",
    "$$\\text{Salary} = ...$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yêu cầu 1b: Xây dựng mô hình sử dụng duy nhất 1 đặc trưng tính cách với các đặc trưng tính cách gồm `conscientiousness`, `agreeableness`, `extraversion`, `nueroticism`, `openess_to_experience`, tìm mô hình cho kết quả tốt nhất (1 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý: khi sử dụng cross-validation, sinh viên cần xáo trộn dữ liệu 1 lần duy nhất và thực hiện trên toàn bộ đặc trưng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phần code cho yêu cầu 1b\n",
    "# Tìm ra đặc trưng tốt nhất\n",
    "# In ra các kết quả cross-validation như yêu cầu\n",
    "\n",
    "# Các đặc trưng tính cách\n",
    "personality_features = ['conscientiousness', 'agreeableness', 'extraversion', 'nueroticism', 'openess_to_experience']\n",
    "\n",
    "# X = X_train[personality_features]\n",
    "\n",
    "# X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Best_Feature(model, features):\n",
    "    best_feature = None\n",
    "    lowest_mae = float('inf')  # Khởi tạo với giá trị dương vô cùng để so sánh\n",
    "    \n",
    "    # Thực hiện K-fold Cross Validation và tìm đặc trưng tốt nhất\n",
    "    for feature in features:\n",
    "        X = X_train[[feature]]\n",
    "        y = y_train\n",
    "    \n",
    "        # Tính MSE bằng K-fold Cross Validation\n",
    "        # Tính MAE bằng K-fold Cross Validation\n",
    "        mae_scores = -cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "        avg_mae = mae_scores.mean()\n",
    "        print(feature , '| MAE =' , avg_mae)\n",
    "        \n",
    "        if avg_mae < lowest_mae:\n",
    "            lowest_mae = avg_mae\n",
    "            best_feature = feature    \n",
    "            \n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conscientiousness | MAE = 124444.48696126812\n",
      "agreeableness | MAE = 123813.28712231014\n",
      "extraversion | MAE = 123914.50490042963\n",
      "nueroticism | MAE = 123738.52541404287\n",
      "openess_to_experience | MAE = 124119.48107191359\n",
      "Salary = 304647.55 + -16021.494*nueroticism \n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện lại mô hình best_personality_feature_model với đặc trưng tốt nhất trên toàn bộ tập huấn luyện\n",
    "# Khởi tạo mô hình hồi quy tuyến tính\n",
    "best_personality_feature_model = LinearRegression()\n",
    "    \n",
    "best_feature = Find_Best_Feature(best_personality_feature_model, personality_features)\n",
    "\n",
    "\n",
    "# Chọn đặc trưng tốt nhất và huấn luyện mô hình trên toàn bộ dữ liệu\n",
    "X_best = X_train[[best_feature]]\n",
    "y_best = y_train\n",
    "\n",
    "best_personality_feature_model.fit(X_best, y_best)\n",
    "\n",
    "\n",
    "best_feature1b = [best_feature]\n",
    "print(CTMoHinh(best_personality_feature_model, best_feature1b))\n",
    "\n",
    "\n",
    "# X_test1b = X_test[[best_feature]]\n",
    "# y_pred1b = best_personality_feature_model.predict(X_test1b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 119361.91739987816\n"
     ]
    }
   ],
   "source": [
    "# Gọi hàm MAE (tự cài đặt hoặc từ thư viện) trên tập kiểm tra với mô hình best_personality_feature_model\n",
    "mae1b = mean_absolute_error(y_test, y_pred1b)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae1b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Công thức hồi quy (phần trọng số làm tròn đến 3 chữ số thập phân, ví dụ 0.012345 $\\to$ 0.012)\n",
    "\n",
    "$$\\text{Salary} = ...$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yêu cầu 1c: Xây dựng mô hình sử dụng duy nhất 1 đặc trưng `English`, `Logical`, `Quant`, tìm mô hình cho kết quả tốt nhất (1 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý: khi sử dụng cross-validation, sinh viên cần xáo trộn dữ liệu 1 lần duy nhất và thực hiện trên toàn bộ đặc trưng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phần code cho yêu cầu 1c\n",
    "# Tìm ra đặc trưng tốt nhất\n",
    "# In ra các kết quả cross-validation như yêu cầu\n",
    "\n",
    "\n",
    "# Các đặc trưng đặc trưng ngoại ngữ, lô-gic, định lượng\n",
    "skill_features = ['English', 'Logical', 'Quant']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English | MAE = 120963.06945762748\n",
      "Logical | MAE = 120037.71893286356\n",
      "Quant | MAE = 117461.46396286949\n",
      "Salary = 117759.73 + 368.852*Quant \n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện lại mô hình best_skill_feature_model với đặc trưng tốt nhất trên toàn bộ tập huấn luyện\n",
    "\n",
    "# Khởi tạo mô hình hồi quy tuyến tính\n",
    "best_skill_feature_model = LinearRegression()\n",
    "    \n",
    "best_feature = Find_Best_Feature(best_skill_feature_model, skill_features)\n",
    "\n",
    " \n",
    "# Chọn đặc trưng tốt nhất và huấn luyện mô hình trên toàn bộ dữ liệu\n",
    "X_best = X_train[[best_feature]]\n",
    "y_best = y_train\n",
    "\n",
    "best_skill_feature_model.fit(X_best, y_best)\n",
    "\n",
    "\n",
    "best_feature1c = [best_feature]\n",
    "print(CTMoHinh(best_skill_feature_model, best_feature1c))\n",
    "\n",
    "\n",
    "X_test1c = X_test[[best_feature]]\n",
    "y_pred1c = best_skill_feature_model.predict(X_test1c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 108814.05968837194\n"
     ]
    }
   ],
   "source": [
    "# Gọi hàm MAE (tự cài đặt hoặc từ thư viện) trên tập kiểm tra với mô hình best_skill_feature_model\n",
    "mse1c = mean_absolute_error(y_test, y_pred1c)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mse1c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Công thức hồi quy (phần trọng số làm tròn đến 3 chữ số thập phân, ví dụ 0.012345 $\\to$ 0.012)\n",
    "\n",
    "$$\\text{Salary} = ...$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yêu cầu 1d: Sinh viên tự xây dựng mô hình, tìm mô hình cho kết quả tốt nhất (3 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý: khi sử dụng cross-validation, sinh viên cần xáo trộn dữ liệu 1 lần duy nhất và thực hiện trên toàn bộ $m$ mô hình mà sinh viên thiết kế"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tìm mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trình bày các phần tìm ra mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thử nghiệm, so sánh các mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phần code cho yêu cầu 1d\n",
    "# Tìm ra mô hình tốt nhất (tự thiết kế bởi sinh viên)\n",
    "# In ra các kết quả cross-validation như yêu cầu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huấn luyện lại mô hình my_best_model trên toàn bộ tập huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gọi hàm MAE (tự cài đặt hoặc từ thư viện) trên tập kiểm tra với mô hình my_best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Công thức hồi quy (phần trọng số làm tròn đến 3 chữ số thập phân, ví dụ 0.012345 $\\to$ 0.012)\n",
    "\n",
    "$$\\text{Salary} = ...$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "15af99fd1a1a3f0a3416ea421564e792a8676a13670c2eed127d89ab0518a27b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
